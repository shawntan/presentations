{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Adjacency constraints in Hidden Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constraining for activation regions\n",
    "\n",
    "Constraints performed by restricting the 1024 layer to a 32 by 32 grid, and then penalising the difference between a cell and the activations of the surrounding cells.\n",
    "\n",
    "<img src=\"images/cellinfluence.png\"/>\n",
    "\n",
    "These constraints wraparound at the edges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Constraint Term\n",
    "\n",
    "We define a term $c$,\n",
    "\n",
    "$$c = \\sqrt{\\sum_{(i,j) \\in H^2,\\text{adjacent}(i,j)} (h_i - h_j)^2}$$\n",
    "\n",
    "Where $H$ are the indices of the cells in the chosen hidden layer. This is then added to the final cost:\n",
    "\n",
    "$$\\hat{L} = L + \\alpha c$$\n",
    "\n",
    "In the following experiments, a value of $\\alpha = 0.0125$ is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiment\n",
    "\n",
    "+ Dataset: TIMIT, using FBank features + energies + deltas (order=2) context of 11 frames\n",
    "+ Kaldi toolkit for feature processing, Theano for neural network training\n",
    "+ Experiments\n",
    "    + Constrained all layers\n",
    "    + Constrained on each layer individually, selected best model by dev set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "| System                       | PER  |\n",
    "|------------------------------|------|\n",
    "| Unconstrained                | 21.1 |\n",
    "| Constrained all layers       | 20.7 |\n",
    "| Constrained on 1 layer (2nd) | 20.7 |\n",
    "\n",
    "Improvements from constrained models, constraining all layers and just 1 give similar results.\n",
    "\n",
    "Selected layer was the second hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plots of the hidden layers\n",
    "\n",
    "Averaged plot of frames with the `aa` phoneme.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td>Unconstrained</td>\n",
    "<td>Constrained</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><img src=\"images/constraint2.png\" width=\"75%\"/> </td>\n",
    "<td><img src=\"images/constraint1.png\" width=\"75%\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Similarities between plots\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td>aa<img src=\"images/layer-0-phn-2.png\" width=\"55%\"/></td>\n",
    "    <td>ae<img src=\"images/layer-0-phn-3.png\" width=\"55%\"/></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>s<img src=\"images/layer-0-phn-37.png\" width=\"55%\"/></td>\n",
    "    <td>z<img src=\"images/layer-0-phn-47.png\" width=\"55%\"/></td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Video for an utterance\n",
    "\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "<source src=\"images/animation--1.mp4\" type=\"video/mp4\"/>\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What can this be useful for?\n",
    "\n",
    "Some ideas for exploiting the behaviour caused by the constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Noise robustness?\n",
    "\n",
    "Intuition: The constraint introduces some form of redundancy to each layer. Redundancy may be helpful in being robust to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Results on noisy test set\n",
    "\n",
    "1. Added 5dB of noise from NoiseX `babble.wav` to test set. \n",
    "2. Ran models trained on clean data on noisy data.\n",
    "\n",
    "| System                       | Clean PER | Noisy PER (5dB) |\n",
    "|------------------------------|-----------|-----------------|\n",
    "| Unconstrained                | 21.1      | 73.9            |\n",
    "| Constrained on 1 layer (1st) | 20.9      | 62.5            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Training on noisy data and testing on noisy data\n",
    "\n",
    "The unconstrained model performs better than the constrained models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Speaker adaptation?\n",
    "\n",
    "Intuition: Exploit the \"blobs\" formed by the constraint.\n",
    "\n",
    "Suppose each speaker forms the similar types of blobs, just in different locations. Can we modify the weights of the feature extractors in the next layer to suit the speaker?\n",
    "\n",
    "<img src=\"images/layer-0-phn-47.png\" width=\"55%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gaussian filters \n",
    "\n",
    "<table style=\"border:0px\">\n",
    "<tr style=\"border:0px\">\n",
    "<td style=\"border:0px;width:40%;\"><img src=\"images/gaussian_filters.png\"></td>\n",
    "<td style=\"border:0px\">\n",
    "We want to learn feature extractors for the input in terms of Gaussian filters with varying width height and rotations.\n",
    "\n",
    "Let the Gaussian function be,\n",
    "\n",
    "    $$ g(\\mathbf{x};\\mathbf{B},\\boldsymbol{\\mu}) = \\exp\\left(-{\\left\\| \\mathbf{B} (\\mathbf{x} - \\boldsymbol{\\mu}) \\right\\|}^2\\right) $$\n",
    "    \n",
    "Then we define a weight matrix $\\mathbf{W}$ between layers such that,\n",
    "\n",
    "$$ \\underbrace{\\mathbf{W}}_{(n,h)} = \\underbrace{\\mathbf{G}}_{(n,k)} \\underbrace{\\mathbf{M}}_{(k,h)}$$\n",
    "\n",
    "where $\\mathbf{M}$ is a standard transformation matrix freely tuned by gradient descent, and $\\mathbf{G}$ is a matrix with each column representing a Gaussian filter:\n",
    "\n",
    "$$\\mathbf{G}_{i,j} = g(\\left[\\text{row}(i),\\text{col}(i)\\right]^\\top;\\mathbf{B}_j,\\boldsymbol{\\mu}_j)$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Updating the Gaussian Filters\n",
    "\n",
    "1. Training the canonical model, update all parameters (with adjacency constraint)\n",
    "2. During adaptation, update all the $\\mathbf{G}$ and $\\boldsymbol{\\mu}$ parameters.\n",
    "\n",
    "\n",
    "Initial experiments with this approach did not work well. Improvements over canonical model are within 0.1-0.2% in PER over the canonical model."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
